{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeakerDiarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMop5OTOaD91K3qMewsIjuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadaAlruwaythi/Speaker-Diarization/blob/main/SpeakerDiarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhQqMcjiKH6J"
      },
      "outputs": [],
      "source": [
        "AUDIO_FILE ='/content/data/V7.wav'\n",
        "y, sr = librosa.load(AUDIO_FILE)\n",
        "Audio(data=y, rate=sr)\n",
        "totDuration = librosa.get_duration(filename=AUDIO_FILE)\n",
        "# Create chunks/windows for feeding into the model\n",
        "division_per_second = 1\n",
        "chunk_time = 1.0 / division_per_second\n",
        "chunk_size = sr // division_per_second\n",
        "\n",
        "remainder_chunks = y.shape[0] % chunk_size\n",
        "num_of_chunks = 1\n",
        "if(remainder_chunks>0):\n",
        "    num_of_chunks = y[:-remainder_chunks].shape[0]/chunk_size\n",
        "    Y = np.split(y[:-remainder_chunks], num_of_chunks)\n",
        "else:\n",
        "    num_of_chunks = y.shape[0]/chunk_size\n",
        "    Y = np.split(y, num_of_chunks)\n",
        "\n",
        "# Extract feature: Mel-frequency Cepstral Coefficients\n",
        "feature_mfcc = np.array([ librosa.feature.mfcc(y=chunk, sr=sr, n_mfcc = 40) for chunk in Y ])\n",
        "feature_mfcc.shape\n",
        "feature_mfcc_mean = np.mean(feature_mfcc, axis = 2)\n",
        "# Extract feature: Spectral flatness\n",
        "feature_spectral_flatness = np.array([librosa.feature.spectral_flatness(y=y) for chunk in Y])\n",
        "feature_spectral_flatness.shape\n",
        "feature_spectral_flatness_mean = np.mean(feature_spectral_flatness, axis = 2)\n",
        "# Extract feature: Spectral flux\n",
        "feature_specflux = np.array([librosa.onset.onset_strength(y=y, sr=sr) for chunk in Y])\n",
        "feature_specflux.shape\n",
        "feature_specflux_mean = np.mean(feature_specflux, axis = 1).reshape(-1,1)\n",
        "# Extract feature: Pitch\n",
        "feature_pitches = np.array([librosa.piptrack(y=y, sr=sr)[0] for chunk in Y])\n",
        "feature_pitches.shape\n",
        "feature_pitches_mean = np.mean(feature_pitches, axis = 2)\n",
        "#Create final feature space for feeding into the model\n",
        "X = np.hstack((\n",
        "    feature_mfcc_mean,\n",
        "    feature_spectral_flatness_mean,\n",
        "    feature_specflux_mean,\n",
        "    feature_pitches_mean\n",
        "))\n",
        "X.shape\n",
        "# Normalize the input\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X.shape\n",
        "from sklearn.mixture import GaussianMixture\n",
        "nclusters = 6\n",
        "gmm = GaussianMixture(n_components=nclusters)\n",
        "gmm.fit(X)\n",
        "\n",
        "op = gmm.predict(X)\n",
        "time_speaker = {}\n",
        "for i in range(len(op)):\n",
        "    time_speaker[i+1] = str(op[i])\n",
        "\n",
        "\n",
        "#Segmentation Algorithm\n",
        "\n",
        "def getCount(time_speaker, cluster, wstart, wend):\n",
        "    count = 0\n",
        "    lastSeenAt = None\n",
        "    for i in range(wstart, wend+1):\n",
        "        if(time_speaker[i] == cluster):\n",
        "            count += 1\n",
        "            lastSeenAt = i\n",
        "    return (count, lastSeenAt)\n",
        "\n",
        "def getSuccessor(time_speaker, currentCluster, wstart, params):\n",
        "    totalDuration = len(time_speaker)\n",
        "    lookahead = int(params['lookaheadTime']/chunk_time)\n",
        "    i = wstart\n",
        "    successorCount = 0\n",
        "    while(i <= totalDuration - lookahead):\n",
        "        j = i + lookahead\n",
        "        successor = time_speaker[i]\n",
        "        if(successor == currentCluster):\n",
        "            return (i, successor)\n",
        "        successorCount = getCount(time_speaker, successor, i, j)\n",
        "        if(successorCount[0] > int(params['epsilon']/chunk_time)):\n",
        "            return (i, successor)\n",
        "        i += 1\n",
        "    i = min(i + lookahead, totalDuration)\n",
        "    return (i, time_speaker[i])\n",
        "            \n",
        "def getBreakPoint(time_speaker, cluster, wstart, params):\n",
        "    totalDuration = len(time_speaker)\n",
        "    i = wstart\n",
        "    end = None\n",
        "    while(time_speaker[i] == cluster):\n",
        "        i += 1\n",
        "    breaker = time_speaker[i]\n",
        "    j = min(i + int(params['lookaheadTime']/chunk_time), totalDuration)\n",
        "    breakerCount = getCount(time_speaker, breaker, i, j)\n",
        "    clusterCount = getCount(time_speaker, cluster, i, j)\n",
        "    if(breakerCount[0] >= int(params['epsilon']/chunk_time)): \n",
        "        end = i\n",
        "    else:\n",
        "        i += 1\n",
        "        successor = getSuccessor(time_speaker, cluster, i, params)\n",
        "        if(successor[1] == cluster):\n",
        "            i = successor[0]\n",
        "            end = getBreakPoint(time_speaker, cluster, i, params)\n",
        "        else:\n",
        "            end = successor[0]\n",
        "    return end\n",
        "\n",
        "def segment(time_speaker, params):\n",
        "    segments = {}\n",
        "    totalDuration = len(time_speaker)\n",
        "    w = 1\n",
        "    recorded = {}\n",
        "    while(w <= totalDuration):\n",
        "        cluster = time_speaker[w]\n",
        "        start = None\n",
        "        end = None\n",
        "        if(recorded.get(cluster) == None):\n",
        "            i = w\n",
        "            j = min(w + int(params['lookaheadTime']/chunk_time), totalDuration)\n",
        "            count = getCount(time_speaker, cluster, i, j)\n",
        "            if(count[0] > int(params['epsilon']/chunk_time)):\n",
        "                start = i\n",
        "                end = getBreakPoint(time_speaker, cluster, start, params)\n",
        "                w = end-1\n",
        "                segments[cluster] = (start, end)            \n",
        "                recorded[cluster] = True\n",
        "                continue\n",
        "        w += 1         \n",
        "    return segments\n",
        "\n",
        "params = {\n",
        "    'lookaheadTime' : 7,\n",
        "    'epsilon' : 4,\n",
        "}\n",
        "segments = segment(time_speaker, params)\n",
        "segments\n",
        "\n",
        "\n",
        "\n",
        "speakers = {}\n",
        "rate, data = wavfile.read('/content/data/V7.wav')\n",
        "i = 1\n",
        "for k in segments:\n",
        "    start = math.ceil(rate * segments[k][0] * chunk_time)\n",
        "    end = math.ceil(rate * segments[k][1] * chunk_time)\n",
        "    speakers[i] = data[start:end+1]\n",
        "    i += 1\n",
        "speakers\n",
        "for i in speakers:\n",
        "    wavfile.write('data/'+str(i)+'.wav', rate, speakers[i])\n",
        "    \n",
        "len(speakers)"
      ]
    }
  ]
}